{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pgmpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-26864acaa327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpgmpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadwrite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBIFReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pgmpy'"
     ]
    }
   ],
   "source": [
    "from pgmpy.readwrite import BIFReader\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BIFReader(\"asia.bif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['asia', 'tub'],\n",
       " ['smoke', 'lung'],\n",
       " ['smoke', 'bronc'],\n",
       " ['lung', 'either'],\n",
       " ['tub', 'either'],\n",
       " ['either', 'xray'],\n",
       " ['bronc', 'dysp'],\n",
       " ['either', 'dysp']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asia': array([[0.01],\n",
       "        [0.99]]),\n",
       " 'tub': array([[0.05, 0.01],\n",
       "        [0.95, 0.99]]),\n",
       " 'smoke': array([[0.5],\n",
       "        [0.5]]),\n",
       " 'lung': array([[0.1 , 0.01],\n",
       "        [0.9 , 0.99]]),\n",
       " 'bronc': array([[0.6, 0.3],\n",
       "        [0.4, 0.7]]),\n",
       " 'either': array([[1., 1., 1., 0.],\n",
       "        [0., 0., 0., 1.]]),\n",
       " 'xray': array([[0.98, 0.05],\n",
       "        [0.02, 0.95]]),\n",
       " 'dysp': array([[0.9, 0.8, 0.7, 0.1],\n",
       "        [0.1, 0.2, 0.3, 0.9]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asia': ['yes', 'no'],\n",
       " 'tub': ['yes', 'no'],\n",
       " 'smoke': ['yes', 'no'],\n",
       " 'lung': ['yes', 'no'],\n",
       " 'bronc': ['yes', 'no'],\n",
       " 'either': ['yes', 'no'],\n",
       " 'xray': ['yes', 'no'],\n",
       " 'dysp': ['yes', 'no']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lung', 'tub']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_parents()['either']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['either']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_children(net, n):\n",
    "\n",
    "    parents = net.get_parents()\n",
    "    l = []\n",
    "    for node in parents:\n",
    "        if n in parents[node]:\n",
    "            l.append(node)\n",
    "    return l\n",
    "\n",
    "get_children(net, 'lung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asia': 1,\n",
       " 'tub': 0,\n",
       " 'smoke': 1,\n",
       " 'lung': 0,\n",
       " 'bronc': 0,\n",
       " 'either': 0,\n",
       " 'xray': 0,\n",
       " 'dysp': 0}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_sample(net):\n",
    "    states = net.get_states()\n",
    "    l = dict()\n",
    "    for node in states:\n",
    "        cardinality = len(states[node]) - 1 \n",
    "        l[node] = random.randint(0, cardinality)\n",
    "        \n",
    "    return l\n",
    "    \n",
    "#print(net.get_values()['asia']*net.get_values()['either'])\n",
    "#joint_prob(net, 'tub')\n",
    "sample = gen_sample(net)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asia': [],\n",
       " 'tub': ['asia'],\n",
       " 'smoke': [],\n",
       " 'lung': ['smoke'],\n",
       " 'bronc': ['smoke'],\n",
       " 'either': ['lung', 'tub'],\n",
       " 'xray': ['either'],\n",
       " 'dysp': ['bronc', 'either']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_parents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asia \n",
      " [[0.01]\n",
      " [0.99]] \n",
      "\n",
      "tub \n",
      " [[0.05 0.01]\n",
      " [0.95 0.99]] \n",
      "\n",
      "smoke \n",
      " [[0.5]\n",
      " [0.5]] \n",
      "\n",
      "lung \n",
      " [[0.1  0.01]\n",
      " [0.9  0.99]] \n",
      "\n",
      "bronc \n",
      " [[0.6 0.3]\n",
      " [0.4 0.7]] \n",
      "\n",
      "either \n",
      " [[1. 1. 1. 0.]\n",
      " [0. 0. 0. 1.]] \n",
      "\n",
      "xray \n",
      " [[0.98 0.05]\n",
      " [0.02 0.95]] \n",
      "\n",
      "dysp \n",
      " [[0.9 0.8 0.7 0.1]\n",
      " [0.1 0.2 0.3 0.9]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def joint_prob(net, n, sample):\n",
    "    values = net.get_values()\n",
    "    \n",
    "    parents = net.get_parents()[n]\n",
    "    children = get_children(net,n)\n",
    "    \n",
    "    value = values[n]\n",
    "    print(n, '\\n', value, '\\n')\n",
    "    \n",
    "    if len(parents) > 0:\n",
    "        \n",
    "        for i in len(value):\n",
    "            parents[i]\n",
    "            \n",
    "            value[i] = value[i]\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    #for node in children:\n",
    "    #    print(node)\n",
    "    #    print(values[node])\n",
    "\n",
    "def gibbs_sampling(net, sample, n_iter=1, debug=1):\n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        # for each value in the sample\n",
    "        for j in sample:\n",
    "            parents = net.get_parents()[j]\n",
    "            children = get_children(net, j)\n",
    "            #if debug: print(parents + children)\n",
    "            joint_prob(net, j, sample)\n",
    "            \n",
    "        \n",
    "    \n",
    "gibbs_sampling(net, sample)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_parents()['smoke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lung', 'tub']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_parents()['either']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "asia_model = net.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "asia_infer = VariableElimination(asia_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 1465.15it/s]\n",
      "Eliminating: asia: 100%|██████████| 7/7 [00:00<00:00, 320.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "| tub      |   phi(tub) |\n",
      "+==========+============+\n",
      "| tub(yes) |     0.0104 |\n",
      "+----------+------------+\n",
      "| tub(no)  |     0.9896 |\n",
      "+----------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Computing the probability of bronc given smoke.\n",
    "q = asia_infer.query(variables=['tub'])\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-f3de9f2f1089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpgmpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayesianModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpgmpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGibbsSampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgibbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGibbsSampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masia_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgibbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pgmpy/sampling/Sampling.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGibbsSampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBayesianModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_kernel_from_bayesian_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMarkovModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_kernel_from_markov_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pgmpy/sampling/Sampling.py\u001b[0m in \u001b[0;36m_get_kernel_from_bayesian_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcard\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcard\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother_cards\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0mprod_cpd_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprod_cpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m                 \u001b[0mkernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprod_cpd_reduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod_cpd_reduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pgmpy/factors/discrete/CPD.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, values, inplace)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mtabular_cpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTabularCPD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular_cpd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mtabular_cpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pgmpy/factors/discrete/DiscreteFactor.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, values, inplace)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         values = [\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_no\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         ]\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pgmpy/factors/discrete/DiscreteFactor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         values = [\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_no\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         ]\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pgmpy/utils/state_name.py\u001b[0m in \u001b[0;36mget_state_no\u001b[0;34m(self, var, state_name)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_to_no\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from pgmpy.models.BayesianModel import BayesianModel\n",
    "from pgmpy.sampling import GibbsSampling\n",
    "gibbs = GibbsSampling(asia_model)\n",
    "gibbs.generate_sample(size=10, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asia_model.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----------+----------+----------+\n",
      "| lung        | lung(yes) | lung(yes) | lung(no) | lung(no) |\n",
      "+-------------+-----------+-----------+----------+----------+\n",
      "| tub         | tub(yes)  | tub(no)   | tub(yes) | tub(no)  |\n",
      "+-------------+-----------+-----------+----------+----------+\n",
      "| either(yes) | 1.0       | 1.0       | 1.0      | 0.0      |\n",
      "+-------------+-----------+-----------+----------+----------+\n",
      "| either(no)  | 0.0       | 0.0       | 0.0      | 1.0      |\n",
      "+-------------+-----------+-----------+----------+----------+\n",
      "+----------+-----------+----------+\n",
      "| asia     | asia(yes) | asia(no) |\n",
      "+----------+-----------+----------+\n",
      "| tub(yes) | 0.05      | 0.01     |\n",
      "+----------+-----------+----------+\n",
      "| tub(no)  | 0.95      | 0.99     |\n",
      "+----------+-----------+----------+\n"
     ]
    }
   ],
   "source": [
    "print(asia_model.get_cpds()[3])\n",
    "print(asia_model.get_cpds()[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['either', 'tub', 'smoke']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asia_model.get_markov_blanket('lung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'z', 'w', 'u', 's', 'v']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "G = BayesianModel([('x', 'y'), ('z', 'y'), ('y', 'w'), ('y', 'v'), ('u', 'w'),\n",
    "                       ('s', 'v'), ('w', 't'), ('w', 'm'), ('v', 'n'), ('v', 'q'), ('z','a')])\n",
    "G.get_markov_blanket('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<TabularCPD representing P(asia:2) at 0x7f773a5adb10>,\n",
       " <TabularCPD representing P(bronc:2 | smoke:2) at 0x7f773a5adcd0>,\n",
       " <TabularCPD representing P(dysp:2 | bronc:2, either:2) at 0x7f773a5add90>,\n",
       " <TabularCPD representing P(either:2 | lung:2, tub:2) at 0x7f773a5ad090>,\n",
       " <TabularCPD representing P(lung:2 | smoke:2) at 0x7f773a5add50>,\n",
       " <TabularCPD representing P(smoke:2) at 0x7f773a602250>,\n",
       " <TabularCPD representing P(tub:2 | asia:2) at 0x7f773a547d50>,\n",
       " <TabularCPD representing P(xray:2 | either:2) at 0x7f773a547f50>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asia_model.get_cpds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_bayesnet\n",
    "from read_bayesnet import BayesianNetwork, Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node :  asia \n",
      "parents :  [] \n",
      "markov blanket :  ['tub'] \n",
      "probs :  {'yes': 0.01, 'no': 0.99} \n",
      "\n",
      "node :  tub \n",
      "parents :  ['asia'] \n",
      "markov blanket :  ['asia', 'lung', 'either'] \n",
      "probs :  {('yes',): {'yes': 0.05, 'no': 0.95}, ('no',): {'yes': 0.01, 'no': 0.99}} \n",
      "\n",
      "node :  smoke \n",
      "parents :  [] \n",
      "markov blanket :  ['lung', 'bronc'] \n",
      "probs :  {'yes': 0.5, 'no': 0.5} \n",
      "\n",
      "node :  lung \n",
      "parents :  ['smoke'] \n",
      "markov blanket :  ['tub', 'smoke', 'either'] \n",
      "probs :  {('yes',): {'yes': 0.1, 'no': 0.9}, ('no',): {'yes': 0.01, 'no': 0.99}} \n",
      "\n",
      "node :  bronc \n",
      "parents :  ['smoke'] \n",
      "markov blanket :  ['smoke', 'either', 'dysp'] \n",
      "probs :  {('yes',): {'yes': 0.6, 'no': 0.4}, ('no',): {'yes': 0.3, 'no': 0.7}} \n",
      "\n",
      "node :  either \n",
      "parents :  ['lung', 'tub'] \n",
      "markov blanket :  ['tub', 'dysp', 'bronc', 'lung', 'xray'] \n",
      "probs :  {('yes', 'yes'): {'yes': 1.0, 'no': 0.0}, ('no', 'yes'): {'yes': 1.0, 'no': 0.0}, ('yes', 'no'): {'yes': 1.0, 'no': 0.0}, ('no', 'no'): {'yes': 0.0, 'no': 1.0}} \n",
      "\n",
      "node :  xray \n",
      "parents :  ['either'] \n",
      "markov blanket :  ['either'] \n",
      "probs :  {('yes',): {'yes': 0.98, 'no': 0.02}, ('no',): {'yes': 0.05, 'no': 0.95}} \n",
      "\n",
      "node :  dysp \n",
      "parents :  ['bronc', 'either'] \n",
      "markov blanket :  ['bronc', 'either'] \n",
      "probs :  {('yes', 'yes'): {'yes': 0.9, 'no': 0.1}, ('no', 'yes'): {'yes': 0.7, 'no': 0.3}, ('yes', 'no'): {'yes': 0.8, 'no': 0.2}, ('no', 'no'): {'yes': 0.1, 'no': 0.9}} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bn = BayesianNetwork(file='asia.bif')  # example usage for the supplied earthquake.bif file\n",
    "for v in bn.variables:\n",
    "    print('node : ',v.name,'\\nparents : ',v.parents,'\\nmarkov blanket : ',v.markov_blanket,'\\nprobs : ',v.probabilities,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
